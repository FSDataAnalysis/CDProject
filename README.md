 
==================================================================
> Coursera: Getting and Cleaning Data Course.
  Project tile: Human Activity Recognition Using Smartphones Dataset.
  This file provides information about this repo, the project,  the scripts, 
  how the scripts work and how they are connected 


May 2014

# BACKGROUND OF THIS PROJECT (REPO)

In this repo, data from the [Human Activity Recognition Using Smartphones Data    Set (HARUS)] (https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip) has been cleaned and processed. A description of the study  can be found [here] (http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). 

In order to clean and process data  from (HARUS) in accordance with the project of the Coursera [Cleaning and getting data course] (https://www.coursera.org/course/getdata) an R script has been coded. The script can be found in this repo (run_analysis.R).  

# DETAILS OF THE WORK 

## USAGE

Run the run_analysis.R file in R. A tidy data set (Tidy_Data_Set) of 180 rows and 88 columns is printed in the R screen. 

## Cleaning and processing the data  

The way in which the processed data sets have been generated is described below. The data sets are also descrbed in the CodeBook.md file. 

The data from (HARUS) has been processed in the following way:

* Merging data

The The rbind () function has been employed to bind the file_X_test.txt and file_X_train.txt files that can be found in the folder generated by unziping the [zip data file] (https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip) provided in the project description of the course.  

The result is a merged data set (merged_data) generated when running the scriptThis is the result of question 1. 

* Adding descriptive variable labels

1. The set of labels has been found in the features.txt file and read into R as a data frame with the function read.table(). This function has been used thorughout to read the files in this work. 

2. The column names have been made lower case with the fucntion tolower(). 

3. The symbols "-", "(", ")", "." and "," have been removed from the names 
with the function gsub().

The result is the a data set with descriptive labels (labled_activities) generated when running the script. This is the result of question 4. 


* Selected variables for a sub set

The data set has been subsetted in order to include the variables that include information about mean (mean) or standard deviation (std). The labels (column names) that included the words mean or dev have been selected with the use of the grep() function. The data set has been then subsetted according to the results of the grep() function. 

The result is a subset of the data set (data_Set_mean_std) generated when running the script. This is the result of question 2. 


* Adding the descriptive activity labels

The labels have been found in the activity_labels.txt file. These have been read into R has detailed above. 

The labels have been made lower case with the fucntion tolower() and then converted to factors with the functions as.factor() and as.character(). 

The levels (labels) have been been passed to the activity column of the data set

The result is a data set (labled_activities) with the level activity with descriptive labels generated when running the script. This is the result of question 3.


* Subsetting and averaging by subject and activity

The subjects and their relation to each row has been found in the files y_train.txt and x_train.txt respectively. These files have been read into R as above and then added as an extra column with the label subject that is numbered from 1 to 30 and with activity names detailed in the CodeBook.md file. 

The functions melt() and dcast() have been employed to identify the id variables "subject" and "activity" while leaving the rest of variables has variables and values. The dcast() function has served to calculate the mean resulting from subsetting for each subject for each activity. 

The data set has been sorted by subject and activity  according to the subject (1 to 30)and activity (walking to laying as detailed in the CodeBook.md file) with the function order(). 

The result is a tidy data set (Tidy_Data_Set). This is the result of question 5.  


## Required files

  In order The working directory should include:

* run_analysis.R

* README.md

* CodeBook.md

* unzipped getdata-projectfiles-UCI HAR Dataset.zip file

 [download zip file](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip)

* Alternatively to 1.4 the unzziped data from getdata-projectfiles-UCI HAR Dataset.zip 

> Provided the zip file has not been downloaed to the current directory,
 the file will be downloaded automatically


# ACKNOWLEDGEMENTS

I found many good tips in the Coursera forum. For the markdown I found from [Eugenio del Prete a good site] (site https://class.coursera.org/getdata-003/forum/thread?thread_id=232). 

I also found some food information googling here and there. 



